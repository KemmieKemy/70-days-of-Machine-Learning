{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 27: 70 Days Pre-Bootcamp Online Class with Data Science Nigeria - Machine Learning Stream #DSN70daysofML\n",
    "SVM Optimization <br>\n",
    "*Notes;*\n",
    "* arange - allows us to define how many steps we want to take.\n",
    "* To know if you've found great values of the weights and bias given SVM is yi(xi.w+b) = 1 is when you hve a value that is relatively close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Support_Vector_Machine:\n",
    "    def__init__(self, visualization = True):\n",
    "        self.visualization = visualization\n",
    "        self.colors = {1:'r',-1:'b'}\n",
    "        if self.visualization:\n",
    "            self.fig = plt.figure()\n",
    "            self.ax = self.fig.agg_subplot(1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "def fit (self, data):\n",
    "    self.data = data\n",
    "    #{||w||: [w,b]}\n",
    "    opt_dict = {}\n",
    "    \n",
    "    #each times there's a vector, it's transformed by the product of these values\n",
    "    transforms = [[1,1],\n",
    "                 [-1,1],\n",
    "                 [-1,-1],\n",
    "                 [1,-1]]\n",
    "    all_data = []\n",
    "    for yi in self.data:\n",
    "        for featureset in self.data(yi):\n",
    "            for featureset in featureset:\n",
    "                all_data.append(feature)\n",
    "    \n",
    "    self.max_feature_value = max(all_data)\n",
    "    self.min_feature_value = min(all_data)\n",
    "    all_data = None\n",
    "    \n",
    "    step_sizes = [self.max_feature_value * 0.1,\n",
    "                 self.max_feature_value * 0.01,\n",
    "                 self.max_feature_value * 0.001]\n",
    "    \n",
    "    b_range_multiple = 5\n",
    "    \n",
    "    b_multiple = 5\n",
    "    \n",
    "    latest_optimum = self.max_feature_value * 10\n",
    "    \n",
    "    for step in step_sizes:\n",
    "        w = np.array{[latest_optimum, latest_optimum]}\n",
    "        #convex\n",
    "        optimized = False\n",
    "        while not optimized:\n",
    "            for b in np.arange(-1*(self.max_feature_value * b_range_multiple),\n",
    "                              self.max_feature_value * b_range_multiple,\n",
    "                              step * b_range_multiple):\n",
    "                for transformation in transforms:\n",
    "                    w_t = w*transformation\n",
    "                    found_option = True\n",
    "                    #weakest link in the SVM fundamentally\n",
    "                    #SMO attempts to fix this a bit\n",
    "                    #yi(xi.w+b) >= 1\n",
    "                    for i in self.data:\n",
    "                        for xi in self.data[i]:\n",
    "                            yi = i \n",
    "                            if not yi*(np.dot(w_t,xi)+b) >= 1:\n",
    "                                found_option = False\n",
    "                                \n",
    "                    if found_option:\n",
    "                        opt_dict[np.linalg.norm(w_t)] = [w_t, b]\n",
    "            if w[0] < 0:\n",
    "                optimized = True\n",
    "                print('Optimized a step')\n",
    "            else:\n",
    "                w = w - step\n",
    "        norms = sorted([n for n in opt_dict])\n",
    "        #||w|| : [w,b]\n",
    "        opt_choice = opt_dict[norms[0]]\n",
    "        \n",
    "        self.w = opt_choice[0]\n",
    "        self.b = opt_choice[1]\n",
    "        latest_optimum = opt_choice[0][0] + step * 2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict (self, features):\n",
    "    #sign(x.w+b)\n",
    "    classification = np.sign(np.dot(array(features),self.w)+self.b)\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {-1: np.array([[1,7],\n",
    "                           [2,8],\n",
    "                          [3,8],]),\n",
    "             1: np.array([[5,1],\n",
    "                         [6,-1],\n",
    "                         [7,3],])}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
